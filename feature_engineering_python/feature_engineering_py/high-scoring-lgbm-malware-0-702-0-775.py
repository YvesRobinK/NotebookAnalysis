#!/usr/bin/env python
# coding: utf-8

# # Microsoft Malware Prediction Competition
# # How To Score Over 0.702 LB with LGBM!
# During the Microsoft Malware Prediction competition, everyone wanted to know how to score over 0.700 LB with a single LGBM. Since the competition is over, we can now discuss the secret 12 engineered features! This model scores 0.702 public LB and 0.775 private LB with a single LGBM. (As part of an ensemble, it scores 0.707 LB [here][2].)
# 
# # Why did this model come in 1435th place?
# The private dataset contains 33% outliers. Those outliers ruin every model's score. This is explained [here][1]. When those outliers are removed, this model scores an amazing 0.775 AUC !!  
#   
# Even if you fit the clean data (sine wave pattern below) perfectly, the presence of outliers adds so much error that your model's AUC is terrible. See model one below. The presence of outliers hurt the most accurate solutions the most. If your solution only fits the data (sine wave pattern) loosely, then you have a chance of being near the outliers and may receive a better private LB score as seen in model two below.
#   
#   
# ![image](http://playagricola.com/Kaggle/errorone31919.png)  
#   
# ![image](http://playagricola.com/Kaggle/errortwo31919.png)
# 
# # Load Data and Fix Pandas Memory Leak  
#   
# [1]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84745
# [2]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84135

# In[1]:


# monkeypatches.py

# Solving memory leak problem in pandas
# https://github.com/pandas-dev/pandas/issues/2659#issuecomment-12021083
import pandas as pd, sys
from ctypes import cdll, CDLL
try:
    cdll.LoadLibrary("libc.so.6")
    libc = CDLL("libc.so.6")
    libc.malloc_trim(0)
except (OSError, AttributeError):
    libc = None

__old_del = getattr(pd.DataFrame, '__del__', None)

def __new_del(self):
    if __old_del:
        __old_del(self)
    libc.malloc_trim(0)

if libc:
    print('Applying monkeypatch for pd.DataFrame.__del__', file=sys.stderr)
    pd.DataFrame.__del__ = __new_del
else:
    print('Skipping monkeypatch for pd.DataFrame.__del__: libc or malloc_trim() not found', file=sys.stderr)


# In[2]:


# SET THIS VARIABLE TO TRUE TO RUN KERNEL QUICKLY AND FIND BUGS
# ONLY 10000 ROWS OF DATA IS LOADED
Debug = False

import numpy as np, pandas as pd, gc, random
import matplotlib.pyplot as plt

def load(x):
    ignore = ['MachineIdentifier']
    if x in ignore: return False
    else: return True

# LOAD TRAIN AND TEST
if Debug:
    df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load,nrows=10000)
else:
    df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load)
df_train['HasDetections'] = df_train['HasDetections'].astype('int8')
if 5244810 in df_train.index:
    df_train.loc[5244810,'AvSigVersion'] = '1.273.1144.0'
    df_train['AvSigVersion'].cat.remove_categories('1.2&#x17;3.1144.0',inplace=True)

if Debug:
    df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load,nrows=10000)
else:
    df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load)
    
print('Loaded',len(df_train),'rows of TRAIN and',len(df_test),'rows of TEST')


# # Define Encoding Functions

# In[3]:


# FREQUENCY ENCODE SEPARATELY
def encode_FE(df,col):
    vc = df[col].value_counts(dropna=False, normalize=True).to_dict()
    nm = col+'_FE'
    df[nm] = df[col].map(vc)
    df[nm] = df[nm].astype('float32')
    return [nm]

# FREQUENCY ENCODE TOGETHER
def encode_FE2(df1, df2, col):
    df = pd.concat([df1[col],df2[col]])
    vc = df.value_counts(dropna=False, normalize=True).to_dict()
    nm = col+'_FE2'
    df1[nm] = df1[col].map(vc)
    df1[nm] = df1[nm].astype('float32')
    df2[nm] = df2[col].map(vc)
    df2[nm] = df2[nm].astype('float32')
    return [nm]

# FACTORIZE
def factor_data(df_train, df_test, col):
    df_comb = pd.concat([df_train[col],df_test[col]],axis=0)
    df_comb,_ = df_comb.factorize(sort=True)
    # MAKE SMALLEST LABEL 1, RESERVE 0
    df_comb += 1
    # MAKE NAN LARGEST LABEL (need to remove attype('str') above)
    df_comb = np.where(df_comb==0, df_comb.max()+1, df_comb)
    df_train[col] = df_comb[:len(df_train)]
    df_test[col] = df_comb[len(df_train):]
    del df_comb
    
# OPTIMIZE MEMORY
def reduce_memory(df,col):
    mx = df[col].max()
    if mx<256:
            df[col] = df[col].astype('uint8')
    elif mx<65536:
        df[col] = df[col].astype('uint16')
    else:
        df[col] = df[col].astype('uint32')
        
# REDUCE CATEGORY CARDINALITY
def relax_data(df_train, df_test, col):
    cv1 = pd.DataFrame(df_train[col].value_counts().reset_index().rename({col:'train'},axis=1))
    cv2 = pd.DataFrame(df_test[col].value_counts().reset_index().rename({col:'test'},axis=1))
    cv3 = pd.merge(cv1,cv2,on='index',how='outer')
    factor = len(df_test)/len(df_train)
    cv3['train'].fillna(0,inplace=True)
    cv3['test'].fillna(0,inplace=True)
    cv3['remove'] = False
    cv3['remove'] = cv3['remove'] | (cv3['train'] < len(df_train)/10000)
    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] < cv3['test']/3)
    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] > 3*cv3['test'])
    cv3['new'] = cv3.apply(lambda x: x['index'] if x['remove']==False else 0,axis=1)
    cv3['new'],_ = cv3['new'].factorize(sort=True)
    cv3.set_index('index',inplace=True)
    cc = cv3['new'].to_dict()
    df_train[col] = df_train[col].map(cc)
    reduce_memory(df_train,col)
    df_test[col] = df_test[col].map(cc)
    reduce_memory(df_test,col)
    
# DISPLAY MEMORY STATISTICS
def display_memory(df_train, df_test):
    print(len(df_train),'rows of training data use',df_train.memory_usage(deep=True).sum()//1e6,'Mb memory!')
    print(len(df_test),'rows of test data use',df_test.memory_usage(deep=True).sum()//1e6,'Mb memory!')

# CONVERT TO CATEGORIES
def categorize(df_train, df_test, cols):
    for col in cols:
        df_train[col] = df_train[col].astype('category')
        df_test[col] = df_test[col].astype('category')


# # Feature Engineering
# Here is half of the secret sauce. You must engineer the following five variables. (The other half is frequency encoding 7 variables described below.). These variables were discovered by trying hundreds of engineered variables to see which ones increased Time Split Validation (TSV explained [here][1]). Each variable was added to the model one at a time and validation score was recorded. Only the follow 5 variables increased validation score.
# 
# * `AppVersion2` indicates whether your Windows Defender is up to date. This is the second number from AppVersion. Regardless of your operating system and version, you can always have AppVersion with second number equal 18. For example, you should have `4.18.1807.18075` instead of `4.12.xx.xx`.
# 
# * `Lag1` is the difference between AvSigVersion_Date and Census_OSVersion_Date. Since AvSigVersion is the virus definitions for Windows Defender, this variable indicates whether Windows Defender is out-of-date by comparing it's last install with the date of the operating system. Out-of-date antivirus indicates that a user either has better antivirus or they don't use their computer often. In either case, they have less HasDetections.
# 
# * `Lag5` is the difference between AvSigVersion_Date and July 26, 2018. The first observation in Microsoft's training data is July 26, 2018. Therefore if a computer has AvSigVersion_Date before this then their antivirus is out-of-date. (The first observation in the test data is September 27, so you use this difference when encoding the test data.)
# 
# * `driveA` is the ratio of harddrive partition used for the operating system with the total hard drive. Savy users install multiple operating systems and have a lower ratio. Savy users have reduced HasDetections.
# 
# * `driveB` is the difference between harddrive partition used for the operating system and total hard drive. Responsible users manager their hard drives well. Responsible users have reduced HasDetections.  
#   
# [1]: https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68

# In[4]:


from datetime import datetime, date, timedelta

# AS timestamp
datedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]
df_train['DateAS'] = df_train['AvSigVersion'].map(datedictAS)
df_test['DateAS'] = df_test['AvSigVersion'].map(datedictAS)

# OS timestamp
datedictOS = np.load('../input/malware-timestamps-2/OSVersionTimestamps.npy')[()]
df_train['DateOS'] = df_train['Census_OSVersion'].map(datedictOS)
df_test['DateOS'] = df_test['Census_OSVersion'].map(datedictOS)

# ENGINEERED FEATURE #1
df_train['AppVersion2'] = df_train['AppVersion'].map(lambda x: np.int(x.split('.')[1]))
df_test['AppVersion2'] = df_test['AppVersion'].map(lambda x: np.int(x.split('.')[1]))

# ENGINEERED FEATURE #2
df_train['Lag1'] = df_train['DateAS'] - df_train['DateOS']
df_train['Lag1'] = df_train['Lag1'].map(lambda x: x.days//7)
df_test['Lag1'] = df_test['DateAS'] - df_test['DateOS']
df_test['Lag1'] = df_test['Lag1'].map(lambda x: x.days//7)

# ENGINEERED FEATURE #3
df_train['Lag5'] = datetime(2018,7,26) - df_train['DateAS']
df_train['Lag5'] = df_train['Lag5'].map(lambda x: x.days//1)
df_train.loc[ df_train['Lag5']<0, 'Lag5' ] = 0
df_test['Lag5'] = datetime(2018,9,27) - df_test['DateAS'] #PUBLIC TEST
df_test['Lag5'] = df_test['Lag5'].map(lambda x: x.days//1)
df_test.loc[ df_test['Lag5']<0, 'Lag5' ] = 0
df_train['Lag5'] = df_train['Lag5'].astype('float32') # allow for NAN
df_test['Lag5'] = df_test['Lag5'].astype('float32') # allow for NAN

# ENGINEERED FEATURE #4
df_train['driveA'] = df_train['Census_SystemVolumeTotalCapacity'].astype('float')/df_train['Census_PrimaryDiskTotalCapacity'].astype('float')
df_test['driveA'] = df_test['Census_SystemVolumeTotalCapacity'].astype('float')/df_test['Census_PrimaryDiskTotalCapacity'].astype('float')
df_train['driveA'] = df_train['driveA'].astype('float32') 
df_test['driveA'] = df_test['driveA'].astype('float32') 

# ENGINNERED FEATURE #5
df_train['driveB'] = df_train['Census_PrimaryDiskTotalCapacity'].astype('float') - df_train['Census_SystemVolumeTotalCapacity'].astype('float')
df_test['driveB'] = df_test['Census_PrimaryDiskTotalCapacity'].astype('float') - df_test['Census_SystemVolumeTotalCapacity'].astype('float')
df_train['driveB'] = df_train['driveB'].astype('float32') 
df_test['driveB'] = df_test['driveB'].astype('float32') 

cols6=['Lag1']
cols8=['Lag5','driveB','driveA']

del df_train['DateAS'], df_train['DateOS'] #, df_train['DateBL']
del df_test['DateAS'], df_test['DateOS'] #, df_test['DateBL']
del datedictAS, datedictOS
x=gc.collect()


# # Frequency Engineering
# This is the second half of the secret sauce. There is a correlation between the frequency of time variables (`EngineVersion`, `AvSigVersion`, `AppVersion`, `Census_OSVersion`, `Census_OSBuildRevision`) and `HasDetections`. This occurs for two reasons explained [here][1]. One reason is a leak and will lead to overfitting train and public test because I believe that private test is a random sample and therefore does not benefit from the leak. The second reason is because out-of-date antivirus produces a front tail with both reduced frequency and reduced HasDetections (explained and verified [here][1]). To take advantage of these two correlations, you need to frequency encode the time variables **separately** for train and test. (Also since EngineVersion and AppVersion have low cardinality, I found that frequency encoded them doesn't increase CV or LB.)  
# 
# There is an actual correlation between frequency of `CountryIdentifier` and `HasDetections`. This is probably because popular countries are targeted. Also there is a true correlation between frequency of `Census_InternalBatteryNumberOfCharges` and `HasDetections`. I have no idea why this is the case. To take advantage of these correlations, frequency encode these variables in train and test **together**. 
#   
# These frequency engineered variables were discovered by trying every variable as FE encoded **separately** and FE encoded **together** to see which ones increased Time Split Validation (TSV explained [here][1]). Each variable was added to the model one at a time and validation score was recorded. Only the follow 7 FE variables increased validation score.
#   
# [1]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84287

# In[5]:


cols3 = []
# ENGINEERED FEATURES #6, #7, #8, #9, #10
FE = ['Census_OSVersion', 'Census_OSBuildRevision', 'Census_InternalBatteryNumberOfCharges', 'AvSigVersion', 'Lag1']
for col in FE:
    cols3 += encode_FE(df_train, col)
    encode_FE(df_test, col)
    
# ENGINEERED FEATURES #11, #12
FE2 = ['CountryIdentifier', 'Census_InternalBatteryNumberOfCharges']
for col in FE2:
    cols3 += encode_FE2(df_train, df_test, col)


# # Categorical versus Numerical Encode
# All 82 explanatory variables except `Census_PrimaryDiskTotalCapacity` and `Census_SystemVolumeTotalCapacity` are actually categorical and not numerical. However if you input them into LGBM as categorical, since their cardinality is so high, it leads to overfitting. Therefore validation shows that it is best to label encode variables (`pd.factorize(df[col],sort=True)`) into ordered integers and input them into LGBM as integers. Then set `num_leaves=2048` and LGBM has no trouble finding the categories anyway.  
#   
# After every variable was changed to dtype integer, each variable was tested one by one to see if making it categorical increases LGBM validation score. It was determined that the following 6 variables increased validation score. By making them categorical you prioritize them. So presumably these are important variables. Notice that they cover the variety of flavors of features. We have two geographical variables, one hardware variable, two software/virus variables, and one miscellenous. Flavors of variables are explained [here][1] called groupings.  
#   
# [1]: https://www.kaggle.com/cdeotte/embeddings-network-malware-0-697-0-773

# In[6]:


CE = ['CountryIdentifier', 'SkuEdition', 'Firewall', 'Census_ProcessorCoreCount', 'Census_OSUILocaleIdentifier', 'Census_FlightRing']


# # Remove Variables
# Every variable was removed one at a time and validation score was recorded. Validation verified that we can remove the following 18 variables without decreasing model accuracy. `MachineIdentifier`, `ProductName`, `IsBeta`, `IsSxsPassiveMode`, `HasTpm`, `AutoSampleOptIn`, `PuaMode`, `UacLuaenable`, `Census_DeviceFamily`, `Census_ProcessorClass`, `Census_IsPortableOperatingSystem`, `Census_IsFlightsDisabled`, `Census_IsVirtualDevice`, `Census_OSSkuName`, `OsVer`, `Census_OSArchitecture`, `Census_OSInstallLanguageIdentifier`, `SMode`. The first one is obvious. The next 12 have more than 98% of their data in one category value. The next 4 correlate with another variable greater than `r=0.99`. And the last variable `SMode` changes is distribution radically over time and leads to decreased CV and LB. The other variables don't decrease validation per say but they don't increase it either, so we remove them.

# In[7]:


cols = [x for x in df_train.columns if x not in ['HasDetections']+CE+cols3+cols6+cols8]
cols2 = CE; ct = 1
    
for col in cols.copy():
    rate = df_train[col].value_counts(normalize=True, dropna=False).values[0]
    if rate > 0.98:
        del df_train[col]
        del df_test[col]
        cols.remove(col)
        ct += 1

rmv3=['Census_OSSkuName', 'OsVer', 'Census_OSArchitecture', 'Census_OSInstallLanguageIdentifier']
rmv4=['SMode']
for col in rmv3+rmv4:
    del df_train[col]
    del df_test[col]
    cols.remove(col)
    ct +=1
    
print('Removed',ct,'variables')
x=gc.collect()


# # Reduce Feature Cardinality
# Many variables have over 1000 category values!! We must reduce cardinality. We will remove any category value that contains 0.01% or less of total data. Additionally to prevent overfitting the train data, we will remove any category value that appears 4x more frequenly in train than test. And we will remove any category value that appears 4x less frequency in train than test. Explained [here][1].
#   
# For example, `EngineVersion` has many category values like `1.1.15100.1`, `1.1.15200.1`, `1.1.15300.6`, etc. The category value `1.1.15300.6` appears 4x more frequently in test than train, therefore we will remove it. We "remove it" by changing that computer's `EngineVersion` to a new category value of `TrashCan`.
#   
# [1]: https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68

# In[8]:


print('Factorizing...')
for col in cols+cols2+cols6:
    factor_data(df_train, df_test, col)
print('Relaxing data...')
for col in cols+cols2: relax_data(df_train, df_test, col)
print('Optimizing memory...')
for col in cols+cols2+cols6:
    reduce_memory(df_train, col)
    reduce_memory(df_test, col)
# Converting 6 variables to categorical
categorize(df_train, df_test, cols2)
    
print('Number of variables is',len(cols+cols2+cols3+cols6+cols8))
display_memory(df_train, df_test)


# # Build and Train LGBM
# We use stratified 5-fold to train our LGBM. The hyperparameters were determined using grid search and Time Split Validation.

# In[9]:


import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold

pred_val = np.zeros(len(df_test))
folds = StratifiedKFold(n_splits=5, shuffle=True)

ct = 0
for idxT, idxV in folds.split(df_train[cols+cols2+cols3+cols6], df_train['HasDetections']):
    # TRAIN LGBM
    ct += 1; print('####### FOLD ',ct,'#########')
    df_trainA = df_train.loc[idxT]
    df_trainB = df_train.loc[idxV]
    model = lgb.LGBMClassifier(n_estimators=10000, colsample_bytree=0.5, objective='binary', num_leaves=2048,
            max_depth=-1, learning_rate=0.04)
    h=model.fit(df_trainA[cols+cols2+cols3+cols6+cols8], df_trainA['HasDetections'], eval_metric='auc',
            eval_set=[(df_trainB[cols+cols2+cols3+cols6+cols8], df_trainB['HasDetections'])], verbose=200,
            early_stopping_rounds=100)
    
    # PREDICT TEST
    del df_trainA, df_trainB; x=gc.collect()
    idx = 0; ct2 = 1; chunk = 1000000
    print('Predicting test...')
    while idx < len(df_test):
        idx2 = min(idx + chunk, len(df_test) )
        idx = range(idx, idx2)
        pred_val[idx] += model.predict_proba(df_test.iloc[idx][cols+cols2+cols3+cols6+cols8])[:,1]
        #print('Finished predicting part',ct2)
        ct2 += 1; idx = idx2


# # Adjust Private Test Predictions
# The private test dataset is 33% outliers, explained [here][1], [here][4], [here][2], and [here][3]. Therefore we must account for these outliers or our private test score will be terrible.  
#   
# [1]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84745
# [2]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84096
# [3]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/84227
# [4]: https://www.kaggle.com/cdeotte/private-leaderboard-0-750

# In[10]:


del df_train; x=gc.collect()
df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',
            usecols=['MachineIdentifier','AvSigVersion'], nrows=len(pred_val))

# CORRECT PREDICTIONS FOR OUTLIERS IN PRIVATE TEST DATASET
from datetime import datetime
datedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]
df_test['Date'] = df_test['AvSigVersion'].map(datedictAS)
df_test['HasDetections'] = pred_val / 5.0
df_test['X'] = df_test['Date'] - datetime(2018,11,20,4,0) 
df_test['X'] = df_test['X'].map(lambda x: x.total_seconds()/86400)
df_test['X'].fillna(0,inplace=True)
s = 5.813888
df_test['F'] = 1.0
df_test['F'] = 1 - df_test['X']/s
df_test.loc[df_test['X']<=0,'F'] = 1.0
df_test.loc[df_test['X']>s,'F'] = 0
df_test['HasDetections'] *= df_test['F']


# # Write Submission File

# In[11]:


# WRITE SUBMISSION FILE
df_test[['MachineIdentifier','HasDetections']].to_csv('submission.csv', index=False)


# # Display Predictions
# First we will display a histogram and next display a time series plot. In the time series plot, you can see how the predictions for the final days November 20, 21, 22, 23, 24, 25 have `HasDetections=0`. Those are the outliers which have been corrected for.

# In[12]:


import matplotlib.pyplot as plt    
b = plt.hist(df_test['HasDetections'], bins=200)


# In[13]:


import calendar, math

def dynamicPlot(data,col, target='HasDetections', start=datetime(2018,4,1), end=datetime(2018,12,1)
                ,inc_hr=0,inc_dy=7,inc_mn=0,show=0.99,top=5,top2=4,title='',legend=1,z=0,dots=False):
    # check for timestamps
    if 'Date' not in data:
        print('Error dynamicPlot: DataFrame needs column Date of datetimes')
        return
    
    # remove detection line if category density is too small
    cv = data[(data['Date']>start) & (data['Date']<end)][col].value_counts(dropna=False)
    cvd = cv.to_dict()
    nm = cv.index.values
    th = show * len(data)
    sum = 0; lnn2 = 0
    for x in nm:
        lnn2 += 1
        sum += cvd[x]
        if sum>th:
            break
    top = min(top,len(nm))
    top2 = min(top2,len(nm),lnn2,top)

    # calculate rate within each time interval
    diff = (end-start).days*24*3600 + (end-start).seconds
    size = diff//(3600*((inc_mn * 28 + inc_dy) * 24 + inc_hr)) + 5
    data_counts = np.zeros([size,2*top+1],dtype=float)
    idx=0; idx2 = {}
    for i in range(top):
        idx2[nm[i]] = i+1
    low = start
    high = add_time(start,inc_mn,inc_dy,inc_hr)
    data_times = [low+(high-low)/2]
    while low<end:
        slice = data[ (data['Date']<high) & (data['Date']>=low) ]
        #data_counts[idx,0] = len(slice)
        data_counts[idx,0] = 5000*len(slice['AvSigVersion'].unique())
        for key in idx2:
            if nan_check(key): slice2 = slice[slice[col].isna()]
            else: slice2 = slice[slice[col]==key]
            data_counts[idx,idx2[key]] = len(slice2)
            if target in data:
                data_counts[idx,top+idx2[key]] = slice2['HasDetections'].mean()
        low = high
        high = add_time(high,inc_mn,inc_dy,inc_hr)
        data_times.append(low+(high-low)/2)
        idx += 1

    # plot lines
    fig = plt.figure(1,figsize=(15,3))
    cl = ['r','g','b','y','m']
    ax3 = fig.add_subplot(1,1,1)
    lines = []; labels = []
    if z==1: ax3.plot(data_times,data_counts[0:idx+1,0],'k')
    for i in range(top):
        tmp, = ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5])
        if dots: ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5]+'o')
        lines.append(tmp)
        labels.append(str(nm[i]))
    ax3.spines['left'].set_color('red')
    ax3.yaxis.label.set_color('red')
    ax3.tick_params(axis='y', colors='red')
    if col!='ones': ax3.set_ylabel('Category Density', color='r')
    else: ax3.set_ylabel('Data Density', color='r')
    #ax3.set_yticklabels([])
    if target in data:
        ax4 = ax3.twinx()
        for i in range(top2):
            ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+":")
            if dots: ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+"o")
        ax4.spines['left'].set_color('red')
        ax4.set_ylabel('Detection Rate', color='k')
    if title!='': plt.title(title)
    if legend==1: plt.legend(lines,labels,loc=2)
    plt.show()
        
# INCREMENT A DATETIME
def add_time(sdate,months=0,days=0,hours=0):
    month = sdate.month -1 + months
    year = sdate.year + month // 12
    month = month % 12 + 1
    day = sdate.day + days
    if day>calendar.monthrange(year,month)[1]:
        day -= calendar.monthrange(year,month)[1]
        month += 1
        if month>12:
            month = 1
            year += 1
    hour = sdate.hour + hours
    if hour>23:
        hour = 0
        day += 1
        if day>calendar.monthrange(year,month)[1]:
            day -= calendar.monthrange(year,month)[1]
            month += 1
            if month>12:
                month = 1
                year += 1
    return datetime(year,month,day,hour,sdate.minute)

# CHECK FOR NAN
def nan_check(x):
    if isinstance(x,float):
        if math.isnan(x):
            return True
    return False


# In[14]:


df_test['ones'] = 1
dynamicPlot(df_test, 'ones', inc_dy=2, legend=0,
        title='Test Predictions. (Dotted line uses right y-axis. Solid uses left.)')


# # Result
# I am very proud of this LGBM. It took thousands of validation tests to discover all the features necessary to achieve LB over 0.702. Every night when I went to bed, I would set my computer running for-loops checking new engineered variables. Additionally this model uses insights from over 1000 EDA plots and 100 pages of research notes!!
# ![image](http://playagricola.com/Kaggle/score32119.png)
