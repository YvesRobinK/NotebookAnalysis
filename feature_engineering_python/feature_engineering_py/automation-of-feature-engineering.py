#!/usr/bin/env python
# coding: utf-8

#  # Quick guide on how to read this notebook. 
#  
#  The goal of this kernel is to automate the feature engineering. To create the following feature I gave mangrove several tables with the id as a joint key: the train file, the ressource file and a train_text file is basically a word to vect matrix with all the most frequent words of the first project summary.
# 
# All features in the new_train dataset starting with "LabelP" are discretised which means original of numeric values have been splited into intervals while similar modalities of categorical values have been clustered together.
# 
# 
# All variables starting with Min, Max, Mean ... are automatically generated by mangrove from two tables. 
# 
# 

# In[1]:


import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="white", context="talk")


# In[2]:


original_train = pd.read_csv("../input/donorschoose-application-screening/train.csv")
new_train = pd.read_csv("../input/automatic/donor_choose_train.csv")


# In[ ]:


original_train.sort_values(by=['id']).head()


# In[5]:


new_train.head()


# In[ ]:


def summarize(col,df):
    o = df.groupby(by=[col])
    t = pd.DataFrame(o.project_is_approved.mean()).reset_index()
    return t[col],t['project_is_approved']


# In[ ]:


created_col =['LabelPCountDistinct(ressources_train.csv.description)',
 'LabelPStdDev(ressources_train.csv.price)',
 'LabelPCount(ressources_train.csv) where quantity <= 1.5',
 'LabelPCountDistinct(ressources_train.csv.description) where price > 14.995',
 'LabelPMin(ressources_train.csv.price) where quantity <= 1.5',
 'LabelPMin(ressources_train.csv.price) where price > 14.995',
 'LabelPCount(ressources_train.csv) where price > 14.995','LabelPMean(train_text.csv.Chromebook)']


# Here I select a handful of automatically created variables to plot. You can play with the other ones !

# In[ ]:


for i in created_col:
    f, (ax1) = plt.subplots(1, 1, figsize=(12, 8))
    if i == 'project_is_approved':continue
    new_x,new_y = summarize(col=i,df=new_train)
    sns.barplot(new_x, new_y, palette="RdBu_r",ax=ax1)
    plt.xlabel('Intervals of '+i)
    plt.ylabel('Mean of project is approved')
    plt.xticks(rotation = 45)


# ## You can see the discretisation work in the two following graphs.

# In[ ]:


plt.figure(figsize=(10,7))
old_x,old_y = summarize('teacher_number_of_previously_posted_projects',original_train)
sns.barplot(old_x,old_y)
plt.title("Without smart discretisation")


# In[ ]:


plt.figure(figsize=(10,7))
new_x,new_y = summarize('LabelPteacher_number_of_previously_posted_projects',new_train)
sns.barplot(new_x,new_y)
plt.title("With smart discretisation")


# # Lets find out by how much this data preprocessing can improve your score !

# In[ ]:




